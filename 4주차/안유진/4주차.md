## MLFQ(Muti Level Feedback Queue)
프로세스의 실행 시간을 미리 알 수 없어도! 응답 시간과 반환 시간을 동시에 최적화한다!
* 여러 개의 큐는 서로 다른 우선순위와 타임 슬라이스를 가짐 
* 보다 높은 우선순위의 큐에 있는 프로세스가 우선 선택됨
* 동일 큐 내에서는 RR(Round-Robin) 적용
* 핵심은 큐 사이의 우선순위를 정하는 것! 프로세스의 실행 특성에 따라 동적으로 우선순위 조정
    * 예: 특정 프로세스가 키보드 입력을 기다리면서 반복적으로 CPU를 양보하면 MLFQ는 그 프로세스의 우선순위를 높게 유지, CPU를 장시간 독점한다면 MLFQ는 그 프로세스의 우선순위를 점차 낮춰감
    * 우선순위 규칙
        * 1: 우선순위가 높은 프로세스가 실행된다.
        * 2: 우선순위가 같은 프로세스끼리는 RR로 실행된다.
        * 3: 뉴비는 최상위 큐에 배치
        * 4: 프로세스가 현재 단계에서 받은 시간을 모두 소진하면 타임 슬라이스 끝나기 전에 CPU를 양보하더라도 한 단계 아래 큐로 이동
        * 5: 특정 주기마다 시스템의 모든 프로세스를 최상위 큐로 이동

### 시도 1: 우선순위 변경
우선순위를 정하기 위해서는 `시스템의 워크로드 특성` 반영
* 워크로드 유형
    * 짧은 CPU 버스트 + 빈번한 I/O를 수행하는 대화형 작업
    * 응답 시간이 중요치 않은 긴 CPU 버스트의 계산 집약적 작업
 #### 예제 1: 긴 CPU 버스트를 가진 프로세스 
  초기에는 높은 우선순위를 받지만 CPU를 계속 점유하면 점점 낮은 우선순위를 가진 큐로 내려가다가 최하위 큐에 머물게 됨
 #### 예제 2: 짦은 프로세스와 함께
  MLFQ는 각 프로세스의 실행 시간을 미리 알 수 없기 때문에 일단 모든 프로세스를 짧은 작업으로 간주하고 높은 우선순위를 부여
  정말 짧은 작업이라면 금방 실행을 마치고 종료할 것이고 긴 작업이라면 점점 우선순위가 강등되다가 최하위 큐에서 머물며 CPU 집약적인 작업임을 드러내게 됨 -> SJF와 유사한 효과 달성
 #### 예제 3: I/O 집약적 프로세스
  I/O 작업이 많은 프로세스의 경우 타임 슬라이스를 다 쓰기 전에 CPU를 양보해서 응답성 확보
  이처럼 MLFQ가 프로세스의 I/O 행동을 고려해 우선순위를 동적으로 조정함으로써 시스템 응답성을 개선
=> 현재 MLFQ의 문제점
1. 기아 상태(starvation) 가능성: 시스템 대화형 작업이 너무 많으면 계산 집약적인 작업들은 CPU 시간을 제대로 할당받지 못 함
2. 스케줄러 악용 위험: 타임 슬라이스가 끝나기 전에 CPU를 양보하면 높은 우선순위를 유지할 수 있다는 특성을 악용해서 타임슬라이스의 99%를 선점하는 상황 발생 가능
3. 시간에 따른 프로세스 특성 변화: MLFQ는 CPU 집약적 작업이 대화형 작업으로 변경될 가능성을 고려하지 못 함

### 시도 2: 우선순위의 상향 조정
* 일정 시간이 경과할 때마다 시스템의 모든 프로세스를 최상위 큐로 이동시킴으로써 다음과 같은 문제 해결
    * 최상위 큐에 있는 동안에는 다른 최우선순위 프로세스들과 CPU를 RR 방식으로 나눠쓰게 되므로 모든 프로세스가 기아 상태에 빠지지 않음을 보장
    * CPU 집약적 작업이 대화형 작업으로 특성이 바뀌더라도 우선순위 상향을 통해 변화를 감지하고 대응 가능
* 그 '일정 시간(voodoo 상수)'을 얼마로 정할 것인지가 중요한 문제
    * voodoo 상수를 너무 크게 잡으면 긴 작업이 계속 기아상태 유지
    * 너무 짧게 잡으면 대화형 작업이 충분한 CPU 시간을 할당받지 못 함

### 시도 3: 더 정확한 시간 측정
* 사용자가 스케줄러를 조작해서 자신에게 유리하게 만드는 것을 방지하는 방어 로직이 필요함
* 실제로 CPU를 사용한 누적 시간 측정
* 프로세스가 현재 단계에서 CPU를 양보한 횟수와 무관하게 정해진 시간 할당량을 모두 소진하면 우선순위가 낮아짐


## 비례 배분
'`공정성`'을 최우선 가치로, 각 작업이나 프로세스에게 일정 비율의 CPU를 보장하는 것을 목표로 함
* 다음에 실행할 프로세스를 추첨을 통해 랜덤하게 선택하되, CPU 시간을 더 많이 할당받아야 할 프로세스에게는 추첨에 당첨될 기회를 더 많이 주는 방식
* 무작위성은 시스템의 동작을 예측하기 어려운 환경에서의 `적응력`과 빠른 의사 결정이 필요한 상황에서 `효율성`을 제공하는 핵심 요소
* 사용하는 자료 구조: `R-B Tree`
    * 실행 중이거나 실행 가능한 프로세스들만 R-B Tree로 관리
    * O(log n) 시간에 다음 실행할 프로세스를 선택하면서도 공정한 CPU 시간 분배를 보장
    * CFS(Completely Fair Scheduler)에서의 R-B Tree 동작 원리
        1. vruntime 기반 정렬
            - vruntime = 실제 실행시간 × (NICE_0_LOAD / 프로세스_weight)
            - 각 프로세스의 vruntime을 키로 사용하여 트리에 저장
            - vruntime이 작을수록 왼쪽, 클수록 오른쪽에 배치
        2. 스케줄링 과정
            - 프로세스 선택: 트리의 가장 왼쪽 노드(최소 vruntime) 선택
            - 실행 후 처리: 실행 완료된 프로세스의 vruntime 업데이트 후 트리에 재삽입
            - 시간 슬라이스: 동적으로 계산된 시간만큼 실행
        3. 공정성 보장
            - 모든 프로세스가 비슷한 vruntime을 갖도록 조정
            - 우선순위(nice value)에 따라 가중치 적용
            - 오래 기다린 프로세스가 자동으로 우선순위 상승
    * R-B Tree를 사용하는 이유
        1. 시간 복잡도 보장
            - 삽입, 삭제, 검색 모두 O(log n) 시간 복잡도
            - 스케줄링에서 빠른 프로세스 선택이 중요하므로 효율적
        2. 자가 균형 특성
            - 트리가 항상 균형을 유지하여 최악의 경우에도 성능 보장
            - 일반 이진 탐색 트리의 편향 문제 해결
        3. 실시간성 요구사항
            - 커널에서는 예측 가능한 성능이 중요
            - 레드블랙트리는 균형 유지로 일정한 성능 보장
* 주요 특징
    * 상대적 중요도의 반영: 각 프로세스에 할당된 추첨권 수는 해당 프로세스의 중요도를 의미
    * 유연한 우선순위 조정: 프로세스의 중요도는 추첨권수를 조정하는 것 만으로도 쉽게 변경 가능. 새로운 프로세스가 추가되거나 기존 프로세스의 우선순위를 바꿔야 할 때 매우 유용
    * 장기적 공정성 보장: 충분히 긴 시간 동안 스케줄링을 수행하면, 각 프로세스는 자신의 추첨권 비율만큼의 CPU 시간을 받게 됨
* 단점
    * 단기적으로 봤을 때 CPU 할당이 불균형해 보임
    * 추첨 수행 & 당첨 프로세스 확인 작업에 오버헤드 발생
* CPU 스케줄링 알고리즘 뿐만이 아니라 네트워크 대역폭 할당, 디스크 I/O 스케줄링 등 컴퓨터 시스템의 다양한 자원 관리 문제에 적용 가능

### 📖 과제
𝐐1. 3개의 작업과 난수 시드 1, 2, 3으로 시뮬레이션한 솔루션을 계산하세요.<br>
𝐀1. 
* 시드 1
    - Job 0 (길이=1, 티켓=84), Job 1 (길이=7, 티켓=25), Job 2 (길이=4, 티켓=44)
    - 완료 순서: Job 0 (시간 2) → Job 2 (시간 6) → Job 1 (시간 12)

* 시드 2:
    - Job 0 (길이=9, 티켓=94), Job 1 (길이=8, 티켓=73), Job 2 (길이=6, 티켓=30)
    - 완료 순서: Job 0 (시간 14) → Job 1 (시간 22) → Job 2 (시간 23)

* 시드 3:
    - Job 0 (길이=2, 티켓=54), Job 1 (길이=3, 티켓=60), Job 2 (길이=6, 티켓=6)
    - 완료 순서: Job 1 (시간 4) → Job 0 (시간 5) → Job 2 (시간 11)

𝐐2. 이제 두 개의 특정 작업으로 실행해 보세요. 각각 길이는 10이지만 하나(작업 0)는 티켓이 1장이고 다른 하나(작업 1)는 100장입니다(예: -l 10:1,10:100). 티켓의 수가 이렇게 불균형할 때 어떤 일이 일어날까요? 작업 1이 완료되기 전에 작업 0이 실행될 수 있을까요? 얼마나 자주 그럴까요? 일반적으로 이러한 티켓 불균형이 복권 스케줄링의 동작에 어떤 영향을 미칠까요?<br>
𝐀2.
  - Job 1이 압도적으로 높은 확률(99%)로 선택됨
  - 시드 1,2 모두에서 Job 1이 먼저 완료되고 Job 0이 나중에 실행됨
  - Job 0이 Job 1 완료 전에 실행될 확률은 매우 낮음 (1/101 ≈ 1%)
  - 티켓 불균형은 CPU 시간 할당의 극심한 불평등을 초래함

𝐐3. 길이가 100이고 티켓 할당이 100으로 동일한 두 개의 작업(-l 100:100,100:100)으로 실행할 때 스케줄러는 얼마나 불공정할까요? 몇 가지 다른 난수 시드로 실행하여 (확률적) 답을 결정하세요; 한 작업이 다른 작업보다 얼마나 일찍 끝나는지에 따라 불공정성이 결정됩니다.<br>
𝐀3.  
lottery scheduling은 확률적 특성상 완전히 공정하지 않으며, 같은 티켓 수를 가져도 결과에 큰 차이가 발생할 수 있음
  - 시드 1: Job 1 (196) → Job 0 (200), 차이: 4
  - 시드 2: Job 1 (190) → Job 0 (200), 차이: 10
  - 시드 3: Job 0 (196) → Job 1 (200), 차이: 4
  - 시드 42: Job 1 (197) → Job 0 (200), 차이: 3
  - 시드 100: Job 1 (185) → Job 0 (200), 차이: 15

  