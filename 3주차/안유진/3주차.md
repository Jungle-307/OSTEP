## CPU 스케줄링 개요
* 프로세스 실행을 위해 문맥 교환(Context Switch) 같은 저수준 기술과, 운영체제 스케줄러의 고수준 정책 이해가 필요
* 스케줄링 정책(Scheduling Policy) = 스케줄링 기법(Scheduling Discipline)
* 기원: 생산 관리(Production Management) → 컴퓨터 시스템으로 확장

#### 핵심 질문
1. 스케줄링 정책은 어떻게 개발할 수 있을까?
2. 설계를 위한 기본 프레임워크는 무엇인가?
3. 필요한 핵심 가정은 무엇인가?
4. 어떤 평가 기준이 중요한가?
5. 초창기 시스템에서 사용된 기본 접근 방식은 무엇인가?

#### 스케줄링 평가 기준
* **반환 시간 (Turnaround Time) (응답성)**
    * 정의: 작업이 도착해서 끝날 때까지 걸린 총 시간(작업 완료 시각 - 도착 시각)
    * 목표: 평균 반환 시간을 최소화해서 전체 시스템 성능과 처리 효율 향상
* **공정성 (Fairness)**
    * 정의: 시스템에 있는 모든 프로세스가 CPU를 일정 수준 이상 고르게 배분받는 것
    * 목표: 특정 프로세스가 무한히 대기하거나 자원 독점하는 상황을 방지함
* 응답성과 공정성은 상충 관계 → 트레이드오프 발생

#### 스케줄링 기법들
    1. 선입선출 (FCFS)
        - 특징: 도착 순서대로 실행 (비선점형)
        - 장점: 구현 간단, 직관적, 공평
        - 단점: 긴 작업이 먼저 오면 짧은 작업이 기다리는 호위 효과(convoy effect) 발생
        - 예시 계산: A(3s), B(5s), C(2s) → 평균 반환시간 7s

    2. 최단 작업 우선 (SJF)
        - 실행 시간이 가장 짧은 작업 먼저 실행
        - 모든 작업이 동시에 도착할 경우 → 최적 알고리즘. 하지만 현실에서는 실행 시간을 알 수 없으므로 비현실적
        - 문제: 늦게 도착한 짧은 작업이 긴 작업 뒤로 밀려나는 convoy effect 발생

    3. 최소 잔여시간 우선 (STCF)
        - SJF의 변형, 선점형
        - 새 작업이 도착할 때마다 현재 작업 잔여 시간과 비교 → 더 짧은 쪽 실행
        - 반환 시간을 최소화
        - 하지만 긴 작업의 응답 시간은 매우 길어질 수 있음

    4. 라운드 로빈 (RR)
        - 시분할 시스템 등장 → 응답성 중요
          - 응답 시간 = 작업 도착 시각 ~ 첫 실행 시각
        - STCF는 반환시간 최적이지만 응답시간은 나쁠 수 있음
        - 각 작업에 타임 슬라이스(time slice) 할당 → 순환 실행
        - 응답 시간 개선
        - 타임 슬라이스 짧을수록 응답성 ↑, 하지만 문맥교환 오버헤드 ↑. 따라서 적절한 타임 슬라이스 길이가 핵심

#### 추가 고려 사항
* **I/O 고려**
    * 실제 시스템에서는 I/O가 빈번하므로 CPU-bound와 I/O-bound 프로세스를 적절히 섞는 것이 중요! 
    * 그래야 CPU-bound 프로세스와 I/O-bound 프로세스가 병렬로 실행되면서 시스템 전체 효율이 올라감
    * I/O 요청 시 프로세스는 Blocked 상태 → CPU 다른 프로세스에 할당
    * I/O 완료 시 Ready 상태로 전환 → 스케줄러가 선택

* **현실적 한계**
    * 실행 시간을 미리 안다는 가정은 비현실적
    * 현대 스케줄러들은 실행 이력, 휴리스틱, 피드백 기법 등을 활용해 근사적인 정책 적용

#### 추가 학습 포인트
1. 스케줄링 목표의 다층화
    * 단순히 반환 시간 단축과 응답 시간 단축 말고도 CPU 스케줄링에는 다음과 같은 목표가 있음
        * Throughput(처리량): 단위 시간당 완료되는 작업 수
        * CPU Utilization(자원 활용률)
        * Fairenes(공정성): Starvation 방지
        * Deadline adherence(실시간성): 특정 작업은 일정 시간 내 반드시 완료되어야 함
    * 현실 시스템은 "trade-off" 조정이 핵심 → 예: 서버는 throughput 중시, 인터랙티브 환경은 응답성 중시
        * I/O 먼저 처리: 사용자 경험 개선 (응답성 ↑), CPU-bound는 손해 볼 수 있음
        * CPU 먼저 처리: throughput ↑, 하지만 응답성 ↓ (예: 터미널 입력 느려짐)
        * 따라서 현대 OS는 `"응답성 보장 + CPU 활용도 최적화"`를 동시에 노림

2. 현대 OS 스케줄러 알고리즘
    * **MLFQ (Multi-Level Feedback Queue)**
        * 응답성 + 공정성 모두를 잡으려는 대표적 방법 → `Linux O(1)` 스케줄러의 기초가 됨
        * CPU를 오래 쓰는 작업은 점점 낮은 우선순위 큐로 강등, I/O 중심 짧은 작업은 높은 우선순위 큐에서 빨리 처리
        * 이런 식으로 CPU-bound 프로세스는 배치 처리로, I/O-bound 프로세스는 반응형으로 최적화

    * **CFS (Completely Fair Scheduler)**
        * 리눅스 커널(2.6 이후)의 기본 스케줄러
        * 가상 런타임(virtual runtime)을 기반으로 CPU 시간을 "공평"하게 분배
        * SJF 최적성을 근사하려고, 과거 실행 시간 기록을 통해 미래 실행 시간을 추정

    * **Real-time Scheduling (RTOS)**
        * Rate Monotonic Scheduling (RMS), Earliest Deadline First (EDF)
        * 산업제어/미션크리티컬 환경에서 중요

3. 스케줄링 + 메모리 관리의 상호작용
    * CPU 스케줄링은 "프로세스를 ready 상태에서 실행"시키지만, 메모리 부족으로 swap 발생 시 실제 실행 불가 → I/O 스케줄링과 결합 필요
    * Linux에서는 CFS + 메모리 pressure + cgroup 조합으로 스케줄링을 조정
        * 메모리 pressure: 메모리가 부족할 때 OOM Killer나 kswapd가 동작해서 메모리 회수
        * cgroup: 프로세스 그룹 단위로 CPU/메모리 자원을 제한/조정
            * 예: 메모리 제한이 걸린 cgroup의 프로세스는 자주 swap을 일으켜서 CPU 스케줄링에도 불리해짐

4. 다중 CPU/멀티코어 환경
    * 단일 CPU 스케줄링에서 멈추지 말고, 멀티코어 스케줄링 고려해보면
        * CPU affinity (프로세스가 특정 코어에서 계속 실행되도록 유지)
        * Load balancing (코어 간 작업 분배)
        * NUMA 아키텍처 최적화

5. Starvation과 Aging
    * SJF/STCF는 짧은 job에 유리 → 긴 job은 starvation 발생
    * 해결책: aging 기법으로 오래 기다린 job의 우선순위를 점점 높임

6. 시스템별 사례
    * Linux: CFS, real-time class (SCHED_FIFO, SCHED_RR)
    * Windows: Priority-based, quantum, dynamic priority boosting
    * MacOS: BSD-derived, per-thread priority queues

#### 요약
* SJF/STCF: 반환시간 최소화 목적
* RR: 응답시간 최소화 목적
* '반환시간 최소화'와 '응답시간 최소화'라는 두 목표는 trade-off 관계
* 실제 시스템은 I/O 고려 필요
* 완벽한 알고리즘은 없으며, 상황에 맞는 최적의 절충안 선택이 중요함!

#### 📖 과제
𝐐1. SJF와 FIFO 스케줄러로 길이가 200인 세 개의 작업을 실행할 때의 응답 시간과 반환 시간을 계산하세요.<br>
𝐀1. 두 스케줄러 모두 동일한 성능이 나온다.
  - 응답 시간: Job 0: 0.00, Job 1: 200.00, Job 2: 400.00 (평균: 200.00)
  - 반환 시간: Job 0: 200.00, Job 1: 400.00, Job 2: 600.00 (평균: 400.00)
    ![](/3주차/안유진/images/1.png)
    ![](/3주차/안유진/images/2.png)

𝐐2. 이제 작업의 길이를 다르게 하여 동일한 작업을 수행해 보세요: 100, 200, 300<br>
𝐀2. 이미 최단 작업 순서대로 정렬되어있기 때문에 마찬가지로 두 스케줄러 모두 동일한 성능을 보인다. 
  - 응답 시간: Job 0: 0.00, Job 1: 100.00, Job 2: 300.00 (평균: 133.33)
  - 반환 시간: Job 0: 100.00, Job 1: 300.00, Job 2: 600.00 (평균: 333.33)
    ![](/3주차/안유진/images/3.png)
    ![](/3주차/안유진/images/4.png)

𝐐3. 이제 RR 스케줄러와 시간 할당량(time-slice)을 1로 하여 동일한 작업을 수행해 보세요.<br>
𝐀3.  
  - 길이 200인 3개 작업: 평균 응답 시간 1.00, 평균 반환 시간 599.00
  - 길이 100,200,300 작업: 평균 응답 시간 1.00, 평균 반환 시간 465.67
    ![](/3주차/안유진/images/5.png)
    ![](/3주차/안유진/images/6.png)

𝐐4. 어떤 유형의 워크로드에 대해 SJF가 FIFO와 동일한 반환 시간을 제공하나요?<br>
𝐀4. 작업들이 이미 실행 시간 순으로 정렬된 경우. 즉, 짧은 작업이 먼저 도착하는 경우 SJF와 FIFO가 동일한 반환 시간을 제공한다.
    ![](/3주차/안유진/images/7.png)
    ![](/3주차/안유진/images/8.png)
    ![](/3주차/안유진/images/9.png)
    ![](/3주차/안유진/images/10.png)

𝐐5. 어떤 유형의 워크로드와 시간 할당량에 대해 SJF가 RR과 동일한 응답 시간을 제공하나요?<br>
𝐀5. 단일 작업만 있는 경우나 time slice가 모든 작업의 길이보다 클 때 SJF와 RR이 동일한 응답 시간을 제공한다.
    ![](/3주차/안유진/images/11.png)
    ![](/3주차/안유진/images/12.png)
    ![](/3주차/안유진/images/13.png)
    ![](/3주차/안유진/images/14.png)

𝐐6. 작업 길이가 증가함에 따라 SJF에서 응답 시간은 어떻게 되나요? 시뮬레이터를 사용하여 이 추세를 보여줄 수 있나요?<br>
𝐀6. 작업 길이가 10배 증가할 때 응답 시간도 선형적으로 10배 증가한다. 
  - 10,20,30: 평균 응답 시간 13.33
  - 100,200,300: 평균 응답 시간 133.33
  - 1000,2000,3000: 평균 응답 시간 1333.33
    ![](/3주차/안유진/images/16.png)

𝐐7. 시간 할당량이 증가함에 따라 RR에서 응답 시간은 어떻게 되나요? N개의 작업이 주어졌을 때 최악의 응답 시간을 제공하는 수식을 작성할 수 있나요?<br>
𝐀7. RR에서 time slice가 증가하면 응답 시간이 선형적으로 증가한다. 마지막 작업의 최악 응답 시간은 (N-1) × q (q = time
  slice)이다. 
  - time slice = 1: 평균 응답 시간 1.00
  - time slice = 10: 평균 응답 시간 10.00
  - time slice = 50: 평균 응답 시간 50.00
    ![](/3주차/안유진/images/17.png)
    ![](/3주차/안유진/images/18.png)
